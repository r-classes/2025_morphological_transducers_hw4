# Домашнее задание №4. Метрики качества, разрешение морфологической неоднозначности

*Дедлайн: 19 июня 23:59.*

Перед вами gold разметка некоторых предложений из [UD_Russian-Taiga](https://github.com/UniversalDependencies/UD_Russian-Taiga). А в words.lexd содержатся разборы почти всех слов из этих предложений (некоторым словам соответствует несколько разборов).

**1.** [Получите разбор предложений](https://agricolamz.github.io/2025_morphological_transducers/08_coverage.html#:~:text=%60%60%60%7Bshell%7D-,%24%20cat%20corpus.txt%20%7C%20hfst%2Dproc%20%2DC%20analyzer.hfstol,-%60%60%60), используя words.lexd (1 балл), сохраните в файл `analysis_01.txt`

**2.** [Посчитайте метрики качества](https://github.com/agricolamz/2025_morphological_transducers/blob/main/examples/08_quality_metrics.ipynb)
- покрытие (0,5 балла)
- точность (0,5 балла)
- полноту (0,5 балла)
- f1-меру (0,5 балла)

**3.** Посчитайте метрики качества с удалением эффекта частотности (при котором каждая пара токен-полный_разбор в gold разметке учитывается только один раз) (2 балла)

**4.** Напишите правила для снятия омонимии слова "после". Сохраните в файл `Surname_hw4_04.cg3`. (при разрешении всех случаев - 3 балла, возможен частичный)

**5.** Посчитайте метрики качества заново
- для всех слов (0,5 балла)
- для уникальных слов (с удалением эффекта частотности) (0,5 балла)

Задание на 10: улучшите качество разбора, разрешив ещё некоторые случаи омонимии
- этого (0,5 балла)
- и (0,25 балла)
- как (0,25 балла)

Допишите правила в файл из пункта 4 и сохраните в `Surname_hw4_06.cg3`.

### Формат сдачи:
- `Surname_hw4_04.cg3`
- `Surname_hw4.ipynb` / `Surname_hw4.sh` со всеми шагами и комментариями
- *`Surname_hw4_06.cg3`

### Комментарии:
- Для подсчёта метрик вы можете использовать код из семинара Python, R (они дают немного разные результаты), а можете написать его самостоятельно, но тогда необходимо прокомментировать, чем ваш подход отличается от предложенного. При наличии разумных объяснений несовпадение с ожидаемым ответом не считается ошибкой.
- Для пункта 3 поправьте код самостоятельно. Если в gold-разметке текст `Пила-NOUN не-PART пила-VERB сок-NOUN ,-PUNCT она-PRON ж-PART пила-NOUN`, то мы считаем, что в корпусе 7 уникальных пар (токен-разбор):
1. пила-NOUN (регистр не учитываем)
2. не-PART
3. пила-VERB
4. сок-NOUN
5. ,-PUNCT
6. она-PRON
7. ж-PART

Покрытие: если пара один раз разбирается, а в другой раз не разбирается, покрытие неполное. Если разбор `Пила-NOUN не-PART пила-VERB сок-NOUN ,-PUNCT она-PRON ж-PART *пила`, то покрытие "пила-NOUN" 0.5, а итоговое значение метрики - 6.5/7≈0.929

Precision, Recall, F1-мера: смотрим все случаи разбора каждой пары. Если пила-NOUN один раз разбирается верно, а в другой раз предлагается один неверный разбор, то precision по этому слову 1/2=0.5.

Если вы считаете, что другой способ разумнее, сделайте по-другому и объясните в комментарии принцип.

- Проверьте, что после снятия омонии у вас улучшилась точность и не ухудшилась полнота.

Если вы используете код на питоне из семинара, у вас в пункте 2 должны получиться такие результаты
```
Покрытие 1: 0.993127147766323

Основы 1
{'mean_precision': 0.9536082474226805, 'mean_recall': 0.9896907216494846, 'mean_f1': 0.961053837342497, 'fin_precision': 0.9171974522292994, 'fin_recall': 0.9896907216494846, 'fin_f1': 0.9520661157024795}

Части речи 1
{'mean_precision': 0.9238258877434137, 'mean_recall': 0.993127147766323, 'mean_f1': 0.938144329896907, 'fin_precision': 0.8304597701149425, 'fin_recall': 0.993127147766323, 'fin_f1': 0.9045383411580594}

Теги 1
{'mean_precision': 0.941008018327606, 'mean_recall': 0.993127147766323, 'mean_f1': 0.9495990836197024, 'fin_precision': 0.8550295857988166, 'fin_recall': 0.993127147766323, 'fin_f1': 0.918918918918919}

Разборы целиком 1
{'mean_precision': 0.9203894616265752, 'mean_recall': 0.9896907216494846, 'mean_f1': 0.9347079037800685, 'fin_precision': 0.8275862068965517, 'fin_recall': 0.9896907216494846, 'fin_f1': 0.9014084507042254}
```

Если вы используете предложенную логику подсчёта, у вас в пункте 3 должны получиться такие результаты
```
Покрытие 2: 0.9888268156424581

Основы 2
{'mean_precision': 0.9804469273743017, 'mean_recall': 0.9832402234636871, 'mean_f1': 0.9739292364990689, 'fin_precision': 0.967032967032967, 'fin_recall': 0.9832402234636871, 'fin_f1': 0.9750692520775622}

Части речи 2
{'mean_precision': 0.9720670391061452, 'mean_recall': 0.9888268156424581, 'mean_f1': 0.9692737430167597, 'fin_precision': 0.9365079365079365, 'fin_recall': 0.9888268156424581, 'fin_f1': 0.9619565217391304}

Теги 2
{'mean_precision': 0.9776536312849162, 'mean_recall': 0.9888268156424581, 'mean_f1': 0.9729981378026071, 'fin_precision': 0.946524064171123, 'fin_recall': 0.9888268156424581, 'fin_f1': 0.9672131147540983}

Разборы целиком 2
{'mean_precision': 0.9664804469273743, 'mean_recall': 0.9832402234636871, 'mean_f1': 0.9636871508379888, 'fin_precision': 0.9312169312169312, 'fin_recall': 0.9832402234636871, 'fin_f1': 0.9565217391304348}
```
